{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from pesq import pesq\n",
    "import os\n",
    "from os import listdir\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import read, write\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment, effects \n",
    "import random\n",
    "from pydub.silence import split_on_silence\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO as aIO\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from pydub import AudioSegment, silence\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function to merge the silence \n",
    "def merge(sil):\n",
    "    ans=[]\n",
    "    check=False\n",
    "    for i in range(1,len(sil)):\n",
    "        tmp=sil[i-1][1]\n",
    "        if tmp==sil[i][0]:\n",
    "            ans.append((sil[i-1][0],sil[i][1]))\n",
    "            check=True\n",
    "        else:\n",
    "            if not check:\n",
    "                ans.append(sil[i-1])\n",
    "            else:    \n",
    "                check=False\n",
    "    if ans[-1][1]!=sil[-1][1]:\n",
    "        ans.append(sil[-1])\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the sound waves\n",
    "def visualize(path: str,sil=None):\n",
    "    raw = wave.open(path)\n",
    "    signal = raw.readframes(-1)\n",
    "    signal = np.frombuffer(signal, dtype =\"int16\")\n",
    "    f_rate = raw.getframerate()\n",
    "    time = np.linspace(\n",
    "        0, # start\n",
    "        len(signal) / f_rate,\n",
    "        num = len(signal)\n",
    "    )\n",
    "    plt.figure(1)\n",
    "    plt.title(\"Sound Wave\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.plot(time, signal)\n",
    "    if sil:\n",
    "        for i in sil:\n",
    "            plt.axvline(x=i[0], color='red') \n",
    "            plt.axvline(x=i[1], color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_silence(path,time):\n",
    "    command=\"ffmpeg -i \"+path+\" -af silencedetect=n=-30dB:d=\"+str(time)+\" -f null -\"\n",
    "    out = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    stdout, stderr = out.communicate()\n",
    "    s=stdout.decode(\"utf-8\")\n",
    "    k=s.split('[silencedetect @')\n",
    "    if len(k)==1:\n",
    "        #print(stderr)\n",
    "        return None\n",
    "        \n",
    "    start,end=[],[]\n",
    "    for i in range(1,len(k)):\n",
    "        x=k[i].split(']')[1]\n",
    "        if i%2==0:\n",
    "            x=x.split('|')[0]\n",
    "            x=x.split(':')[1].strip()\n",
    "            end.append(float(x))\n",
    "        else:\n",
    "            x=x.split(':')[1]\n",
    "            x=x.split('size')[0]\n",
    "            x=x.replace('\\r','')\n",
    "            x=x.replace('\\n','').strip()\n",
    "            start.append(float(x))\n",
    "    return list(zip(start,end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg -i ../speech.wav -af silencedetect=n=-30dB:d=5 -f null -'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m files\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m../speech.wav\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     lst\u001b[39m=\u001b[39mdetect_silence(file,\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(lst)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m lst:\n",
      "\u001b[1;32m/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetect_silence\u001b[39m(path,time):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     command\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mffmpeg -i \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mpath\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m -af silencedetect=n=-30dB:d=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(time)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m -f null -\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     out \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(command, stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcommunicate()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/ipnb/FFMPEG.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     s\u001b[39m=\u001b[39mstdout\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/whisper/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    972\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    973\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    974\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    975\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    976\u001b[0m                         errread, errwrite,\n\u001b[1;32m    977\u001b[0m                         restore_signals,\n\u001b[1;32m    978\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    979\u001b[0m                         start_new_session)\n\u001b[1;32m    980\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/whisper/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg -i ../speech.wav -af silencedetect=n=-30dB:d=5 -f null -'"
     ]
    }
   ],
   "source": [
    "files=['/Users/dmitryshlymovich/workspace/wisper/voice-assistant-chatgpt/speech.wav']\n",
    "\n",
    "for file in files:\n",
    "    lst=detect_silence(file,5)\n",
    "    print(lst)\n",
    "    if lst:\n",
    "        visualize(file,lst)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
