{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "import os ,time\n",
    "import voice\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "\n",
    "# transcriberregTrans=voice.WhisperRegTrnscriber()\n",
    "\n",
    "messages = Queue()\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Audio settings\n",
    "STEP_IN_SEC: int = 1    # We'll increase the processable audio data by this\n",
    "LENGHT_IN_SEC: int = 6    # We'll process this amount of audio data together maximum\n",
    "NB_CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = RATE\n",
    "# Visualization (expected max number of characters for LENGHT_IN_SEC audio)\n",
    "MAX_SENTENCE_CHARACTERS = 80\n",
    "\n",
    "CHANNELS = 1\n",
    "FRAME_RATE = 16000\n",
    "RECORD_SECONDS = 20\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 2\n",
    "\n",
    "\n",
    "stats: Dict[str, List[float]] = {\"overall\": [], \"transcription\": [], \"postprocessing\": []}\n",
    "\n",
    "\n",
    "def callbackFunc(recognizer,audio):                          # this is called from the background thread\n",
    "    \n",
    "\n",
    "    try:\n",
    "        \n",
    "        transcription_start_time = time.time()\n",
    "        # transcription,_ =transcriberregTrans.transcribeLang(audio.)\n",
    "        transcription=recognizer.recognize_whisper(audio,language='he')\n",
    "        # print(transcription)\n",
    "        transcription_end_time = time.time()\n",
    "\n",
    "        # transcription = \" \".join(segments)\n",
    "        \n",
    "        # remove anything from the text which is between () or [] --> these are non-verbal background noises/music/etc.\n",
    "        # transcription = re.sub(r\"\\[.*\\]\", \"\", transcription)\n",
    "        # transcription = re.sub(r\"\\(.*\\)\", \"\", transcription)\n",
    "        # We do this for the more clean visualization (when the next transcription we print would be shorter then the one we printed)\n",
    "        transcription = transcription.ljust(MAX_SENTENCE_CHARACTERS, \" \")\n",
    "\n",
    "        transcription_postprocessing_end_time = time.time()\n",
    "        print(transcription)\n",
    "        with output:\n",
    "            display(transcription)\n",
    "        # output.append_stdout(transcription)\n",
    "\n",
    "        # print(transcription, end='\\r', flush=True)\n",
    "\n",
    "        overall_elapsed_time = transcription_postprocessing_end_time - transcription_start_time\n",
    "        transcription_elapsed_time = transcription_end_time - transcription_start_time\n",
    "        postprocessing_elapsed_time = transcription_postprocessing_end_time - transcription_end_time\n",
    "        stats[\"overall\"].append(overall_elapsed_time)\n",
    "        stats[\"transcription\"].append(transcription_elapsed_time)\n",
    "        stats[\"postprocessing\"].append(postprocessing_elapsed_time)\n",
    "\n",
    "                \n",
    "                # print(\"You said \" + recognizer.recognize_whisper(audio,language='he'))  # received audio data, now need to recognize it\n",
    "    except LookupError:\n",
    "        # with output:\n",
    "        #     display(\"Oops! Didn't catch that\")\n",
    "        print(\"Oops! Didn't catch that\")\n",
    "\n",
    "\n",
    "\n",
    "def start_voice_r():\n",
    "    \n",
    "    print(\"Starting\")\n",
    "    # with output:\n",
    "    #         display(\"Starting...\")\n",
    "            \n",
    "    if  messages.empty():\n",
    "        messages.put(True)\n",
    "    \n",
    "    \n",
    "        r = sr.Recognizer()\n",
    "        m = sr.Microphone()\n",
    "        with m as source:\n",
    "            # r.energy_threshold = 270\n",
    "            \n",
    "            r.pause_threshold = 0.8  # seconds of non-speaking audio before a phrase is considered complete \n",
    "            r.phrase_threshold = 0.3  # minimum seconds of speaking audio before we consider the speaking audio a phrase - values below this are ignored (for filtering out clicks and pops)\n",
    "            r.non_speaking_duration = 0.4  # seconds of non-speaking audio to keep on both sides of the recording\n",
    "            r.dynamic_energy_threshold = True\n",
    "            r.adjust_for_ambient_noise(source)  # we only need to calibrate once, before we start listening\n",
    "\n",
    "        # start listening in the background (note that we don't have to do this inside a `with` statement)\n",
    "        stop_listening = r.listen_in_background(source=m, callback=callbackFunc,phrase_time_limit=LENGHT_IN_SEC)\n",
    "\n",
    "    \n",
    "        with output:\n",
    "            display(\"Starting...\")\n",
    "            \n",
    "        while not messages.empty():\n",
    "            time.sleep(1)   \n",
    "    \n",
    "        stop_listening()\n",
    "        print('stoped')\n",
    "    else:\n",
    "        pass    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fabe596705a45fbbb377250e0e83b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Record', icon='microphone', style=ButtonStyle(), tooltip='Record')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aca18c53da45fe8c77a0f08d7c4459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='stop', style=ButtonStyle(), tooltip='Stop')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da905d9647ca4389a8e88827823c92ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " פשוט חייה                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " רמצו, מה besser בהלנים? האם? זהו גם מרובה בכלל                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoped\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "record_button = widgets.Button(\n",
    "    description='Record',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Record',\n",
    "    icon='microphone'\n",
    ")\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='warning',\n",
    "    tooltip='Stop',\n",
    "    icon='stop'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def start_recording(data):\n",
    "    \n",
    "    record = Thread(target=start_voice_r)\n",
    "    record.start()\n",
    "        \n",
    "    # with output:\n",
    "    #     display(\"Starting...\")\n",
    "            \n",
    "        \n",
    "\n",
    "def stop_recording(data):\n",
    "    messages.get_nowait()\n",
    "    messages.task_done()\n",
    "    # with output:\n",
    "        # display(\"Stopping.\")\n",
    "        \n",
    "    \n",
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "display(record_button, stop_button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
